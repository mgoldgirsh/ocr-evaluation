{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use EasyOCR to perform the OCR tasks\n",
    "# Used to evaluate the effectiveness of my OCR model\n",
    "\n",
    "# !pip install easyocr\n",
    "import easyocr\n",
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the documents with easyocr\n",
    "# calculates accuracy with easyocr modified\n",
    "def calculate_accuracy(model, documents_dir: str, results_dir: str): \n",
    "    \"\"\"To calculate accuracy for the OCR model we have a set of labeled documents in the documents dir \n",
    "       and a set of labeled result translations (human labeled). The accuracy metric will calculate the perctange \n",
    "       of letters similar between the expected OCR and the actual result.\n",
    "       \n",
    "       Difference is calculated with a range of 0-1 with a difference of 0 meaning the documents are similar and a difference of 1 \n",
    "       meaning that the documents are very different\n",
    "    Args:\n",
    "        model (_type_): the model used to perform the ocr\n",
    "        documents_dir (str): the documents directory where to perform OCR\n",
    "        results_dir (str): the results directory where to compare results with\n",
    "    \"\"\"\n",
    "    for fname in os.listdir(documents_dir): \n",
    "        cur_path = os.path.join(documents_dir, fname)\n",
    "        difference = 0\n",
    "        \n",
    "        if not os.path.isfile(cur_path) or Path(cur_path).suffix not in [\".png\", \".jpeg\", \".jpg\", \".webp\"]: \n",
    "            continue\n",
    "        \n",
    "        results = model.readtext(cur_path)\n",
    "        results = [result[1] for result in results]  # get only the text detection \n",
    "        \n",
    "        # Calculate expected count\n",
    "        expected_count = {}\n",
    "        for s in results:\n",
    "            for c in list(s):\n",
    "                if c not in expected_count:\n",
    "                    expected_count[c] = 1\n",
    "                else:\n",
    "                    expected_count[c] += 1\n",
    "                \n",
    "        # Calculate actual count\n",
    "        if Path(fname).with_suffix('.txt').name in os.listdir(results_dir):\n",
    "            actual_fpath = os.path.join(results_dir, Path(fname).with_suffix('.txt'))\n",
    "        else:\n",
    "            continue\n",
    "        # Calculate actual count\n",
    "        with open(actual_fpath, 'r') as f:\n",
    "            actual_txt = f.read()\n",
    "            \n",
    "        actual_count = {}\n",
    "        total_chars = 0\n",
    "        for c in actual_txt:\n",
    "            if c not in actual_count:\n",
    "                actual_count[c] = 1\n",
    "            else:\n",
    "                actual_count[c] += 1\n",
    "            total_chars += 1\n",
    "            \n",
    "        # Now compare similarity between the two\n",
    "        for key, value in actual_count.items(): \n",
    "            if key in expected_count: \n",
    "                actual_count[key] -= expected_count[key]\n",
    "                \n",
    "        for key, value in actual_count.items():\n",
    "            if value > 0: \n",
    "                difference += value\n",
    "        \n",
    "        difference = difference / total_chars\n",
    "        \n",
    "        print(f'Difference between {cur_path} and ocr is: {difference}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between documents/doc3.webp and ocr is: 0.037037037037037035\n",
      "Difference between documents/doc1.png and ocr is: 0.03724247226624406\n",
      "Difference between documents/doc2.png and ocr is: 0.007042253521126761\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy between the easy ocr and the actual docs\n",
    "calculate_accuracy(reader, \"documents\", \"results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
